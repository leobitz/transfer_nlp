{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGen(data=\"data/wolayitta_clean.txt\")\n",
    "\n",
    "n_features = len(char2int)\n",
    "n_steps_in = dg.max_root_len\n",
    "n_steps_out = dg.max_output_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dg.words) * .7)\n",
    "batch_size = 128\n",
    "n_batches = int(len(dg.words) * .7 / batch_size) \n",
    "gen = dg.cnn_gen_data(batch_size=batch_size, n_batches=n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, infenc, infdec = conv_model(n_features, n_features, dg.word_feat_len, 64, 256)\n",
    "train.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train.fit_generator(gen, steps_per_epoch=n_batches, epochs = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_n_batches, test_batch_size =  int(len(dg.words) * .7 / batch_size), batch_size  \n",
    "test_n_batches, test_batch_size = 30, 100 \n",
    "test_gen = dg.cnn_gen_data(batch_size=test_batch_size, n_batches=test_n_batches, trainset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(test_n_batches):\n",
    "    [X1, X2, X3], y = next(test_gen)\n",
    "    for j in range(test_batch_size):\n",
    "        X33 = X3[j].reshape((1, X3.shape[1])) \n",
    "        X11 = X1[j].reshape((1, X1.shape[1], X1.shape[2], 1))\n",
    "        target = predict(infenc, infdec, X11, X33, n_steps_out, n_features)\n",
    "        root = ''.join(dg.one_hot_decode(X1[j]))#.replace('&', ' ')\n",
    "        word = ''.join(dg.one_hot_decode(y[j]))#.replace('&', ' ')\n",
    "        targetS = ''.join(dg.one_hot_decode(target))#.replace('&', ' ')\n",
    "        sims.append(dg.word_sim(word, targetS))\n",
    "        if dg.one_hot_decode(y[j]) == dg.one_hot_decode(target):\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(root, word.split('&')[0], '\\t\\t', targetS.split('&')[0])\n",
    "        if root.strip() in targetS.strip():\n",
    "            in_word += 1\n",
    "#     print(b, root, word, targetS)\n",
    "    total += test_batch_size\n",
    "    \n",
    "word_sim_average = sum(sims)/len(sims)\n",
    "print('Word Similarity Average: {0:.2f}%'.format(word_sim_average))\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))\n",
    "print('Word in Accuracy: %.2f%%' % (float(in_word)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
