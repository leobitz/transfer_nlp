{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed\n",
    "from tensorflow.keras.layers import Concatenate, Flatten\n",
    "from tensorflow.keras.layers import GRU, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# from tensorflow.keras.utils.vis_utils import plot_model\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "# from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_multi_lstm(n_input, n_output, n_feature, n_units, feat_units=5):\n",
    "    root_word_input = Input(shape=(15, 28, 1), name=\"root_word_input\")\n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    x = Conv2D(20, (5, 5), padding='same', activation='relu', name=\"cnn\")(root_word_input)\n",
    "    x = MaxPooling2D(3, 3, name=\"pooling\")(x)\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "    x = Dense(n_units - feat_units, activation='relu', name=\"cnn_encoder\")(x)\n",
    "\n",
    "    state = Concatenate(name=\"concatnate\")([x, feat_out])\n",
    "    state_h = Dense(n_units, activation='relu', name='state_h')(state)\n",
    "    state_c = Dense(n_units, activation='relu', name='state_c')(state)\n",
    "    state = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_gru = LSTM(n_units, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _, _= decoder_gru(decoder_inputs, initial_state=state)\n",
    "\n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([root_word_input, decoder_inputs, feature_input], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, feature_input], [state_h, state_c])\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_gru(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h, decoder_state_input_c], [decoder_outputs, state_h, state_c])\n",
    "\n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# data generator\n",
    "dg = DataGen(data=\"data/wolaytta-train.txt\")\n",
    "\n",
    "# length of a word\n",
    "n_input_length = len(char2int)\n",
    "n_steps_in = dg.max_root_len\n",
    "n_steps_out = dg.max_output_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10346.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14780 * .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train data:  561794.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Total train data: \", len(dg.words) * .7)\n",
    "batch_size = 128\n",
    "# number of batches to train\n",
    "n_batches = int(len(dg.words) * .7 / batch_size) \n",
    "\n",
    "# python generator to generate training data at each request\n",
    "# E.x word_matrix, feature = next(gen)\n",
    "gen = dg.cnn_gen_data_multi_word(batch_size=batch_size, n_batches=n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infenc - inference encoder model\n",
    "# infdec - inference decoder model\n",
    "# train - training model that combines both\n",
    "# n_input_length - the length of the input and the output\n",
    "# word_feat_len - the length of the word feature vector\n",
    "# n_units - size of the hidden memory in the RNN\n",
    "train, infenc, infdec = conv_multi_lstm(n_input_length, n_input_length, dg.word_feat_len + 3, 256)\n",
    "train.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0721 21:26:17.121429  5592 deprecation.py:323] From C:\\Users\\amany\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4389/4389 [==============================] - 266s 61ms/step - loss: 0.1635\n",
      "Epoch 2/3\n",
      "4389/4389 [==============================] - 263s 60ms/step - loss: 0.0052\n",
      "Epoch 3/3\n",
      "4389/4389 [==============================] - 263s 60ms/step - loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "# model train given the data generator, how many batches and number of epochs\n",
    "history = train.fit_generator(gen, steps_per_epoch=n_batches, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "dg2 = DataGen(data=\"data/wolaytta-test.txt\")\n",
    "test_n_batches, test_batch_size =  int(len(dg2.words) * 1. / batch_size), batch_size  \n",
    "# test_n_batches, test_batch_size = 30, 10 \n",
    "\n",
    "# data generator for test data\n",
    "test_gen = dg2.cnn_gen_data_multi_word(batch_size=test_batch_size, n_batches=test_n_batches, trainset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(infenc, infdec, inputs, n_steps, cardinality):\n",
    "    # encode\n",
    "    state_h, state_c = infenc.predict(inputs)\n",
    "    state = [state_h, state_c]\n",
    "    # start of sequence input\n",
    "    start = [0.0 for _ in range(cardinality)]\n",
    "#     start[0] = 1\n",
    "    target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        \n",
    "        yhat, h, c= infdec.predict([target_seq] + state)\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Accuracy: 64.57%\n"
     ]
    }
   ],
   "source": [
    "# shows sample examples and calculates accuracy\n",
    "\n",
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(test_n_batches):\n",
    "    # get data from test data generator\n",
    "    [X1, X2, X3], y = next(test_gen)\n",
    "    for j in range(test_batch_size):\n",
    "        word_features = X3[j].reshape((1, X3.shape[1])) \n",
    "        root_word_matrix = X1[j].reshape((1, X1.shape[1], X1.shape[2], 1))\n",
    "#         word_index = X4[j].reshape((1, X4.shape[1]))\n",
    "        # predicts the target word given root word and features\n",
    "        target = predict(infenc, infdec, [root_word_matrix, word_features], n_steps_out, n_input_length)\n",
    "        root = ''.join(dg.one_hot_decode(X1[j]))#.replace('&', ' ')\n",
    "        word = ''.join(dg.one_hot_decode(y[j]))#.replace('&', ' ')\n",
    "        targetS = ''.join(dg.one_hot_decode(target))#.replace('&', ' ')\n",
    "#         sims.append(dg.word_sim(word, targetS))\n",
    "        \n",
    "        # checks if the predicted and the real words are equal\n",
    "        if ''.join(dg.one_hot_decode(y[j])).strip() == ''.join(dg.one_hot_decode(target)).strip():\n",
    "            correct += 1\n",
    "#         else:\n",
    "#             print(root, word.split('&')[0], '\\t\\t', targetS.split('&')[0])\n",
    "#         if root.strip() in targetS.strip():\n",
    "#             in_word += 1\n",
    "#     print(b, root, word, targetS)\n",
    "    total += test_batch_size\n",
    "    \n",
    "\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = open(\"data/wol-multi.txt\").readlines()\n",
    "for i in range(10):\n",
    "    print(dg.roots[i], dg.words[i], dg.word_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2feat, word2root= {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line in lines:\n",
    "#     line = line[:-1].split(' ')\n",
    "#     word2feat[line[0]] = line[1]\n",
    "#     word2root[line[0]] = line[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = {}\n",
    "# for word in word2feat:\n",
    "#     root = word2feat[word]\n",
    "#     feat = word2root[word]\n",
    "#     key = root + \" \" + feat\n",
    "#     if key not in check:\n",
    "#         check[key] = []\n",
    "#     check[key].append(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# file = open(\"data/wol-m.txt\", \"w\")\n",
    "# for key in check.keys():\n",
    "#     words = check[key]\n",
    "#     for i in range(len(words)):\n",
    "#         word = words[i]\n",
    "#         line = \"{0} {1} {2}\\n\".format(word, key, i)\n",
    "#         file.write(line)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
