{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess as pre\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2int, feat2val, max_r, max_w = pre.process(['wol'])\n",
    "data = pre.convert(char2int, feat2val, max_r, max_w, langs=['wol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2char = {val: key for val, key in enumerate(char2int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 14780 Total Batches 115\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_root = max_r + 2\n",
    "max_word = max_w + 2\n",
    "n_feature = data[1].shape[1]\n",
    "hidden_size = 256\n",
    "feat_embed_size = 32\n",
    "char_embed_size = 32\n",
    "n_batches = len(data[0]) // batch_size\n",
    "print(\"Total Data: {0} Total Batches {1}\".format(len(data[0]), n_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pre.gen(data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_multi_model_emb(vocab_size, input_length, decoder_input, dec_output_length, \n",
    "                    n_feature, hidden_size, feat_units = 15, embed_size=64):\n",
    "    root_word_input = Input(shape=(input_length, ), name=\"root_word_input\")\n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_embedding\")(feature_input)\n",
    "    embedding = Embedding(vocab_size, embed_size, input_length=input_length, name=\"char_embedding\")\n",
    "    x = embedding(root_word_input)\n",
    "    \n",
    "    x = Reshape([input_length, embed_size, 1])(x)\n",
    "#     x = keras.backend.expand_dims(x, -1)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Concatenate()([x, feat_out])\n",
    "    state_h = Dense(hidden_size, activation=\"relu\", name=\"state_h\")(x)\n",
    "\n",
    "    decoder_inputs = Input(shape=(None,), name=\"target_word_input\")\n",
    "    emb_dec = embedding(decoder_inputs)\n",
    "    \n",
    "    decoder_gru = GRU(hidden_size, return_sequences=True,\n",
    "                      return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _ = decoder_gru(emb_dec, initial_state=state_h)\n",
    "\n",
    "    decoder_dense = Dense(dec_output_length, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([root_word_input, feature_input, decoder_inputs], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, feature_input], state_h)\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "    decoder_outputs, state_h = decoder_gru(emb_dec, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, encoder, decoder = conv_multi_model_emb(vocab_size=len(char2int), input_length=max_root, \n",
    "                                      decoder_input=max_word, dec_output_length=len(char2int),\n",
    "                                      n_feature=n_feature, hidden_size=hidden_size, \n",
    "                                      feat_units=feat_embed_size, embed_size=char_embed_size)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "target_word_input (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "root_word_input (InputLayer)    [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (Embedding)      multiple             928         root_word_input[0][0]            \n",
      "                                                                 target_word_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 17, 32, 1)    0           char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 17, 32, 32)   320         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 8, 16, 32)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "word_feature_input (InputLayer) [(None, 59)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "feature_embedding (Dense)       (None, 32)           1920        word_feature_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4128)         0           flatten[0][0]                    \n",
      "                                                                 feature_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "state_h (Dense)                 (None, 256)          1057024     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 256),  222720      char_embedding[1][0]             \n",
      "                                                                 state_h[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "train_output (Dense)            (None, None, 29)     7453        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,290,365\n",
      "Trainable params: 1,290,365\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 00:37:38.685996 13412 deprecation.py:323] From C:\\Users\\amany\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "115/115 [==============================] - 12s 103ms/step - loss: 1.6542\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 8s 70ms/step - loss: 1.1998\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.8912\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.5870\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.3857\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.2630\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.1887\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.1321\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.1061\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0777\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 8s 67ms/step - loss: 0.0652\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0516\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0408\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 8s 67ms/step - loss: 0.0321\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0337\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 8s 67ms/step - loss: 0.0223\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 8s 67ms/step - loss: 0.0176\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0150\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 8s 65ms/step - loss: 0.0612\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0217\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0118: 0s - loss: 0.011\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0090\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0080\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0072\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0063\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0057\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0070: 0s \n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0057\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0042\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0046\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0048\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0054\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0065\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0095\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0083\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 8s 65ms/step - loss: 0.0028\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0024\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0020\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0018\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0026\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 8s 65ms/step - loss: 0.0024\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0019\n",
      "Epoch 43/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0035\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0998\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.0202\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0070\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0044\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0035\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.0028\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(gen, steps_per_epoch=n_batches, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4352\n"
     ]
    }
   ],
   "source": [
    "test_data = pre.convert(char2int, feat2val, max_r, max_w, langs=['wol'], train_set=False)\n",
    "test_n_batches, test_batch_size =  int(test_data[0].shape[0] / batch_size), batch_size  \n",
    "print(test_n_batches * test_batch_size)\n",
    "test_gen = pre.gen(data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(infenc, infdec, inputs, n_steps):\n",
    "    # encode\n",
    "    state = infenc.predict(inputs)\n",
    "#     start of sequence input\n",
    "    target_seq = np.array([char2int['<']]*len(inputs[0])).reshape((len(inputs[0]), 1))\n",
    "#     start[0] = 1\n",
    "#     target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    outputs = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h = infdec.predict([target_seq, state])\n",
    "        # store prediction\n",
    "#         output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = h\n",
    "#         print(yhat.shape)\n",
    "        # update target sequence\n",
    "        target_seq = yhat.argmax(axis=2)\n",
    "#         print(target_seq.shape)\n",
    "        outputs.append(target_seq)\n",
    "    return np.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Accuracy: 99.74%\n"
     ]
    }
   ],
   "source": [
    "# shows sample examples and calculates accuracy\n",
    "test_batches = len(test_data[0]) // batch_size\n",
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(test_batches - 1):\n",
    "    # get data from test data generator\n",
    "    [root, feat, dec_in], y = next(test_gen)\n",
    "    pred = predict(encoder, decoder, [root, feat], max_word)\n",
    "    for k in range(batch_size):\n",
    "        indexes = pred[:, k].flatten()\n",
    "        r = ''.join(pre.index_to_word(root[k], int2char)).strip()[1:-1]\n",
    "        w = ''.join(pre.index_to_word(dec_in[k], int2char)).strip()[1:-1]\n",
    "        t = ''.join(pre.index_to_word(indexes, int2char)).strip()[:-1]\n",
    "        if w == t:\n",
    "            correct += 1\n",
    "        \n",
    "\n",
    "    total += batch_size\n",
    "    \n",
    "\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 99.29 99.74"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
