{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen import *\n",
    "from models import *\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 31\n"
     ]
    }
   ],
   "source": [
    "# data generator\n",
    "dg = DataGen(data=\"data/wolayitta_clean.txt\")\n",
    "\n",
    "# length of a word\n",
    "n_input_length = len(char2int)\n",
    "n_steps_in = dg.max_root_len\n",
    "n_steps_out = dg.max_output_len\n",
    "print(n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train data:  579040.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total train data: \", len(dg.words) * .7)\n",
    "batch_size = 128\n",
    "# number of batches to train\n",
    "n_batches = int(len(dg.words) * .7 / batch_size) \n",
    "\n",
    "# python generator to generate training data at each request\n",
    "# E.x word_matrix, feature = next(gen)\n",
    "gen = dg.onehot_gen_data(batch_size=batch_size, n_batches=n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, infenc, infdec = onehot_model(len(dg.root2int), n_input_length, dg.word_feat_len, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "root_word_input (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 251)       605412      root_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "word_feature_input (InputLayer) [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 251)          0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "feature_output (Dense)          (None, 5)            165         word_feature_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "target_word_input (InputLayer)  [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatnate (Concatenate)        (None, 256)          0           flatten[0][0]                    \n",
      "                                                                 feature_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (UnifiedGRU)        [(None, None, 256),  219648      target_word_input[0][0]          \n",
      "                                                                 concatnate[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "train_output (Dense)            (None, None, 28)     7196        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 832,421\n",
      "Trainable params: 832,421\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "4523/4523 [==============================] - 219s 48ms/step - loss: 0.1718\n",
      "Epoch 2/6\n",
      "4523/4523 [==============================] - 217s 48ms/step - loss: 0.0052\n",
      "Epoch 3/6\n",
      "4523/4523 [==============================] - 217s 48ms/step - loss: 0.0029\n",
      "Epoch 4/6\n",
      "4523/4523 [==============================] - 217s 48ms/step - loss: 0.0022\n",
      "Epoch 5/6\n",
      "4523/4523 [==============================] - 217s 48ms/step - loss: 0.0021\n",
      "Epoch 6/6\n",
      "4523/4523 [==============================] - 217s 48ms/step - loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "history = train.fit_generator(gen, steps_per_epoch=n_batches, epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_n_batches, test_batch_size =  int(len(dg.words) * .7 / batch_size), batch_size  \n",
    "test_n_batches, test_batch_size = 30, 100 \n",
    "\n",
    "# data generator for test data\n",
    "test_gen = dg.onehot_gen_data(batch_size=test_batch_size, n_batches=test_n_batches, trainset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Accuracy: 38.03%\n"
     ]
    }
   ],
   "source": [
    "# shows sample examples and calculates accuracy\n",
    "\n",
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(test_n_batches):\n",
    "    # get data from test data generator\n",
    "    [X1, X2, X3], y = next(test_gen)\n",
    "    for j in range(test_batch_size):\n",
    "        word_features = X3[j].reshape((1, X3.shape[1])) \n",
    "        root_word_matrix = X1[j].reshape((1, 1))\n",
    "        \n",
    "        # predicts the target word given root word and features\n",
    "        target = predict(infenc, infdec, root_word_matrix, word_features, n_steps_out, n_input_length)\n",
    "        root = dg.int2word[X1[j]]#.replace('&', ' ')\n",
    "        word = ''.join(dg.one_hot_decode(y[j]))#.replace('&', ' ')\n",
    "        targetS = ''.join(dg.one_hot_decode(target))#.replace('&', ' ')\n",
    "        sims.append(dg.word_sim(word, targetS))\n",
    "#         print(root)\n",
    "        # checks if the predicted and the real words are equal\n",
    "        if dg.one_hot_decode(y[j]) == dg.one_hot_decode(target):\n",
    "            correct += 1\n",
    "#         else:\n",
    "#             print(root, word.split('&')[0], '\\t\\t', targetS.split('&')[0])\n",
    "#         if root.strip() in targetS.strip():\n",
    "#             in_word += 1\n",
    "#     print(b, root, word, targetS)\n",
    "    total += test_batch_size\n",
    "    \n",
    "\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2word = {dg.int2word[key]: key for key in list(dg.int2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 0.9, 11.77, 0.07, 2.7, 128, 48.2, 6.13, 9.53, 13.4, 25.7]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[256, 28.47, 35.45, 35.76, 128, 4.97, 18.20]\n",
    "[64, 0.90, 11.77, 0.07, 2.7, 128, 48.2, 6.13, 9.53, 13.4, 25.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
