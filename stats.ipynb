{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data_gen import *\n",
    "from models import *\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.layers import Concatenate, Flatten\n",
    "from keras.layers import GRU, Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "import numpy as np\n",
    "from autoencoder_data_gen import AEDataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = AEDataGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = da.autoencoder_gen_data()\n",
    "batch_size = 128\n",
    "n_batches = int(len(da.gwords) * .3 / batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17164\n"
     ]
    }
   ],
   "source": [
    "# [x1, x2], y = next(gen)\n",
    "print(len(da.wwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5120"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_word_len = 0\n",
    "# for word in gofa_data_generator.words:\n",
    "#     if len(word) > max_word_len:\n",
    "#         max_word_len = len(word)\n",
    "#         print(word)\n",
    "# print(max_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_model(n_input, n_output, n_units):\n",
    "    root_word_input = Input(shape=(23, 28, 1), name=\"root_word_input\")\n",
    "\n",
    "    x = Conv2D(20, (5, 5), padding='same', activation='relu', name=\"cnn\")(root_word_input)\n",
    "    x = MaxPooling2D(3, 3, name=\"pooling\")(x)\n",
    "\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "\n",
    "    state_h = Dense(n_units, activation='relu', name=\"cnn_encoder\")(x)\n",
    "    \n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_gru = GRU(n_units, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _= decoder_gru(decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([root_word_input, decoder_inputs], decoder_outputs)\n",
    "    encoder_model = Model(root_word_input, state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_outputs, state_h= decoder_gru(decoder_inputs, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "def predict(infenc, infdec, source, cardinality):\n",
    "    # encode\n",
    "    state = infenc.predict([source])\n",
    "    # start of sequence input\n",
    "    start = [0.0 for _ in range(cardinality)]\n",
    "#     start[0] = 1\n",
    "    target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(27):\n",
    "        # predict next char\n",
    "        yhat, h= infdec.predict([target_seq, state])\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = h\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return np.array(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_length = len(da.char2int)\n",
    "model, encoder_model, decoder_model = conv_model(n_input_length, n_input_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "93/93 [==============================] - 10s 112ms/step - loss: 1.4874\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.9446\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 0.7189\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 0.5173\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 0.4058\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.3096\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 0.2304\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 0.1846\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 0.1305\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.0982\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.0759\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 6s 66ms/step - loss: 0.0601\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 0.0477\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 0.0394\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.0333\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.0272\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.0208\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.0213\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.0156: 1\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 0.0118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(gen, steps_per_epoch=n_batches, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  5120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g_test_batches = int(len(da.wwords) * .3 / batch_size) \n",
    "gen3 = da.autoencoder_gen_data(batch_size=batch_size, n_batches=g_test_batches, trainset=False)\n",
    "print(\"Train size: \", (g_test_batches * batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walalloos               walalloos \t\t walaaloos\n",
      "burccetoos              burccetoos \t\t burcuetoos\n",
      "handdaraashadinaa       handdaraashidanaa \t\t handdarashatanaa\n",
      "metootawsu              metootawsu \t\t meeootawsu\n",
      "shatimmikke             shatimmikke \t\t shaametikke\n",
      "zarddaoos               zarddaoos \t\t zardadoos\n",
      "modhdhas                mol''aas \t\t modhdhaas\n",
      "harshshuushas           harshshuushaas \t\t harshshushays\n",
      "ekkays                  ekkays \t\t kkkays\n",
      "inddetaasuoos           inddetaasuoos \t\t inddettayooss\n",
      "shuuyadinaa             shuuyidanaa \t\t shuusidanaa\n",
      "bundduruuqas            bundduruuqaas \t\t bundduruqays\n",
      "gahettoos               gayttoos \t\t gahettoos\n",
      "sulumuumadinaa          sulumuumidanaa \t\t sulumummidanaa\n",
      "kiyadinaa               kiyidanaa \t\t kiyyidanaa\n",
      "abaraadays              abaraadays \t\t abaraabays\n",
      "priixas                 priixaas \t\t piixxaas\n",
      "sheedhdhees             sheedhdhees \t\t sheeddhdees\n",
      "hiraqoos                hiraqoos \t\t hiraqqoos\n",
      "wodalladinaa            wodallidanaa \t\t wodaalidanaa\n",
      "takkaaroos              takkaaroos \t\t aakkaaroos\n",
      "kaachchifatawsu         kaachchifatawsu \t\t kaachchifafawsu\n",
      "tas                     taas \t\t tays\n",
      "milxxixxawsu            milxxixxawsu \t\t milxiixxawsu\n",
      "hanttukays              hanttukays \t\t hanttuyays\n",
      "danddalettawsu          danddayettawsu \t\t danddalettawsu\n",
      "xinggimaaloos           xinggimaaloos \t\t xinggimalloos\n",
      "eeyikke                 eeyyikke \t\t eeyykke\n",
      "undduwaalays            undduwaalays \t\t undduwaalaws\n",
      "xoobadinaa              xoobidanaa \t\t xoobbidanaa\n",
      "purccadinaa             purccidanaa \t\t puuccidanaa\n",
      "hambburuucoos           hambburuucoos \t\t hambburuchoos\n",
      "sholloorettas           sholloorettaas \t\t sholooohettoas\n",
      "xannaoos                xannaoos \t\t xannayoos\n",
      "Exact Accuracy: 91.15%\n"
     ]
    }
   ],
   "source": [
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(3):\n",
    "    # get data from test data generator\n",
    "    [X1, X2], y = next(gen3)\n",
    "    for j in range(batch_size):\n",
    "        root_word_matrix = X1[j].reshape((1, X1.shape[1], X1.shape[2], 1))\n",
    "\n",
    "        # predicts the target word given root word and features\n",
    "        target = predict(encoder_model, decoder_model, root_word_matrix, n_input_length)\n",
    "        root = ''.join(da.one_hot_decode(X1[j]))#.replace('&', ' ')\n",
    "        word = ''.join(da.one_hot_decode(y[j]))#.replace('&', ' ')\n",
    "        targetS = ''.join(da.one_hot_decode(target))#.replace('&', ' ')\n",
    "#         sims.append(dg.word_sim(word, targetS))\n",
    "        \n",
    "        # checks if the predicted and the real words are equal'\n",
    "#         print(len(da.one_hot_decode(y[j])), len(da.one_hot_decode(target)))\n",
    "#         print(len(dg.one_hot_decode(target)[:27]))\n",
    "#         print(len(y[j]))\n",
    "        if da.one_hot_decode(y[j]) == da.one_hot_decode(target)[:23]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(root, word.split('&')[0], '\\t\\t', targetS.split('&')[0])\n",
    "        if root.strip() in targetS.strip():\n",
    "            in_word += 1\n",
    "#     print(b, root, word, targetS)\n",
    "    total += batch_size\n",
    "    \n",
    "\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90.36, 88.28, 92.71, 91.15, 87.5, 92.45]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[90.36, 88.28, 92.71, 91.15, 87.5, 92.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85.42, 71.35, 81.77, 85.42, 89.32, 87.76]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[85.42, 71.35, 81.77, 85.42, 89.32, 87.76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.487, 0.945, 0.719, 0.517, 0.406, 0.31, 0.23, 0.185, 0.13, 0.098, 0.076, 0.06, 0.048, 0.039, 0.033, 0.027, 0.021, 0.021, 0.016, 0.012, "
     ]
    }
   ],
   "source": [
    "for i in [str(x) for x in np.round(history.history['loss'], 3)]:\n",
    "    print(i + ',', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
