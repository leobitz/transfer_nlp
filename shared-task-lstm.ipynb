{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess as pre\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed\n",
    "from tensorflow.keras.layers import Concatenate, Flatten\n",
    "from tensorflow.keras.layers import GRU, Conv2D, MaxPooling2D, Embedding\n",
    "from tensorflow.keras.layers import Input, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2int, feat2val, max_r, max_w = pre.process()\n",
    "data = pre.convert(char2int, feat2val, max_r, max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2char = {val: key for val, key in enumerate(char2int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pre.gen(data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 12595 Total Batches 98\n"
     ]
    }
   ],
   "source": [
    "max_root = max_r + 2\n",
    "max_word = max_w + 2\n",
    "n_feature = data[1].shape[1]\n",
    "hidden_size = 256\n",
    "feat_embed_size = 32\n",
    "char_embed_size = 32\n",
    "n_batches = len(data[0]) // batch_size\n",
    "print(\"Total Data: {0} Total Batches {1}\".format(len(data[0]), n_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_model(vocab_size, input_length, decoder_input, dec_output_length, \n",
    "                    n_feature, hidden_size, feat_units = 15, embed_size=64):\n",
    "    root_word_input = Input(shape=(input_length, ), name=\"root_word_input\")\n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_embedding\")(feature_input)\n",
    "    embedding = Embedding(vocab_size, embed_size, input_length=input_length, name=\"char_embedding\")\n",
    "    x = embedding(root_word_input)\n",
    "    \n",
    "    x = Reshape([input_length, embed_size, 1])(x)\n",
    "#     x = keras.backend.expand_dims(x, -1)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Concatenate()([x, feat_out])\n",
    "    state_h = Dense(hidden_size, activation='relu')(x)\n",
    "    state_c = Dense(hidden_size, activation='relu')(x)\n",
    "    state = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, ), name=\"target_word_input\")\n",
    "    emb_dec = embedding(decoder_inputs)\n",
    "    \n",
    "    decoder_lstm_1 = LSTM(hidden_size, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_output_1, _, _= decoder_lstm_1(emb_dec, initial_state=state)\n",
    "    \n",
    "    decoder_lstm_2 = LSTM(hidden_size, return_sequences=True, return_state=True, name=\"layer2lstm\")\n",
    "    decoder_output_2, _, _ = decoder_lstm_2(decoder_output_1, initial_state=state)\n",
    "    \n",
    "    decoder_dense = Dense(dec_output_length, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_output_2)\n",
    "    \n",
    "    model = Model([root_word_input, feature_input, decoder_inputs], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, feature_input], state)\n",
    "    \n",
    "    decoder_state_input_1 = [Input(shape=(hidden_size,)), Input(shape=(hidden_size,))]\n",
    "    decoder_state_input_2 = [Input(shape=(hidden_size,)), Input(shape=(hidden_size,))]\n",
    "    decoder_state_input = decoder_state_input_1 + decoder_state_input_2\n",
    "    \n",
    "    decoder_output_1, state_h_1, state_c_1 = decoder_lstm_1(emb_dec, initial_state=decoder_state_input_1)\n",
    "    decoder_output_2, state_h_2, state_c_2 = decoder_lstm_2(decoder_output_1, initial_state=decoder_state_input_2)\n",
    "\n",
    "    states = [state_h_1, state_c_1, state_h_1, state_c_1]\n",
    "    decoder_outputs = decoder_dense(decoder_output_2)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_state_input, [decoder_outputs] + states)\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, encoder, decoder = embed_model(vocab_size=len(char2int), input_length=max_root, \n",
    "                                      decoder_input=max_word, dec_output_length=len(char2int),\n",
    "                                      n_feature=n_feature, hidden_size=hidden_size, \n",
    "                                      feat_units=feat_embed_size, embed_size=char_embed_size)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0728 22:38:45.557881 10284 deprecation.py:323] From C:\\Users\\amany\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "98/98 [==============================] - 16s 165ms/step - loss: 1.5945\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 1.2743\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 11s 112ms/step - loss: 1.2161\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 11s 112ms/step - loss: 1.1502\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.9976\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.8067\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.6425\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.5038\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.3659\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.2691\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.1962\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.1465\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.1140\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0914\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0773\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0626\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0562\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0489\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0413\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0347\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0303\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0284\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0269\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0213\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0182\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0175\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.2128\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0399\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0247\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0174\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0138\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0115\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0095\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0092\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0082\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0082\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0149\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0058\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0046\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0037\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0033\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0027\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0025\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0023\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0021\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0018\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0016\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 11s 114ms/step - loss: 0.0015\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0015\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 11s 113ms/step - loss: 0.0190\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(gen, steps_per_epoch=n_batches, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pre.convert(char2int, feat2val, max_r, max_w, train_set=False)\n",
    "test_gen = pre.gen(test_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(infenc, infdec, inputs, n_steps):\n",
    "    # encode\n",
    "    state = infenc.predict(inputs)\n",
    "#     start of sequence input\n",
    "    state = [state[0], state[1], state[0], state[1]]\n",
    "    target_seq = np.array([char2int['<']]*len(inputs[0])).reshape((len(inputs[0]), 1))\n",
    "#     start[0] = 1\n",
    "#     target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    outputs = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h1, c1, h2, c2 = infdec.predict([target_seq] + state)\n",
    "        # store prediction\n",
    "#         output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = [h1, c1, h2, c2]\n",
    "#         print(yhat.shape)\n",
    "        # update target sequence\n",
    "        target_seq = yhat.argmax(axis=2)\n",
    "#         print(target_seq.shape)\n",
    "        outputs.append(target_seq)\n",
    "    return np.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Accuracy: 0.12%\n"
     ]
    }
   ],
   "source": [
    "# shows sample examples and calculates accuracy\n",
    "test_batches = len(test_data[0]) // batch_size\n",
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(test_batches - 1):\n",
    "    # get data from test data generator\n",
    "    [root, feat, dec_in], y = next(test_gen)\n",
    "    pred = predict(encoder, decoder, [root, feat], max_word)\n",
    "    for k in range(batch_size):\n",
    "        indexes = pred[:, k].flatten()\n",
    "        r = ''.join(pre.index_to_word(root[k], int2char)).strip()[1:-1]\n",
    "        w = ''.join(pre.index_to_word(dec_in[k], int2char)).strip()[1:-1]\n",
    "        t = ''.join(pre.index_to_word(indexes, int2char)).strip()[:-1]\n",
    "        if w == t:\n",
    "            correct += 1\n",
    "        \n",
    "\n",
    "    total += batch_size\n",
    "    \n",
    "\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
