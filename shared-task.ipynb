{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess as pre\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed\n",
    "from tensorflow.keras.layers import Concatenate, Flatten\n",
    "from tensorflow.keras.layers import GRU, Conv2D, MaxPooling2D, Embedding\n",
    "from tensorflow.keras.layers import Input, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gen import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2int, feat2val, max_r, max_w = pre.process()\n",
    "data = pre.convert(char2int, feat2val, max_r, max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2char = {val: key for val, key in enumerate(char2int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pre.gen(data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 120121 Total Batches 938\n"
     ]
    }
   ],
   "source": [
    "max_root = max_r + 2\n",
    "max_word = max_w + 2\n",
    "n_feature = data[1].shape[1]\n",
    "hidden_size = 256\n",
    "feat_embed_size = 32\n",
    "char_embed_size = 32\n",
    "n_batches = len(data[0]) // batch_size\n",
    "print(\"Total Data: {0} Total Batches {1}\".format(len(data[0]), n_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_model(vocab_size, input_length, decoder_input, dec_output_length, \n",
    "                    n_feature, hidden_size, feat_units = 15, embed_size=64):\n",
    "    root_word_input = Input(shape=(input_length, ), name=\"root_word_input\")\n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_embedding\")(feature_input)\n",
    "    embedding = Embedding(vocab_size, embed_size, input_length=input_length, name=\"char_embedding\")\n",
    "    x = embedding(root_word_input)\n",
    "    \n",
    "    x = Reshape([45, 32, 1])(x)\n",
    "#     x = keras.backend.expand_dims(x, -1)\n",
    "    x = Conv2D(32, (5, 5), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(hidden_size - feat_units, activation='relu')(x)\n",
    "    state_h = Concatenate()([x, feat_out])\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, ), name=\"target_word_input\")\n",
    "    emb_dec = embedding(decoder_inputs)\n",
    "    decoder_gru = GRU(hidden_size, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _= decoder_gru(emb_dec, initial_state=state_h)\n",
    "    \n",
    "    decoder_dense = Dense(dec_output_length, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([root_word_input, feature_input, decoder_inputs], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, feature_input], state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "    decoder_outputs, state_h= decoder_gru(emb_dec, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [\n",
    "                          decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, encoder, decoder = embed_model(vocab_size=len(char2int), input_length=max_root, \n",
    "                                      decoder_input=max_word, dec_output_length=len(char2int),\n",
    "                                      n_feature=n_feature, hidden_size=hidden_size, \n",
    "                                      feat_units=feat_embed_size, embed_size=char_embed_size)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 00:29:26.159852  1884 deprecation.py:323] From C:\\Users\\amany\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.7631\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 137s 146ms/step - loss: 0.3138\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 136s 145ms/step - loss: 0.1971\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 136s 145ms/step - loss: 0.1446\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 137s 146ms/step - loss: 0.1134\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 138s 147ms/step - loss: 0.0932\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 138s 147ms/step - loss: 0.0793\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 138s 147ms/step - loss: 0.0685\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 137s 146ms/step - loss: 0.0607\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 136s 145ms/step - loss: 0.0544\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(gen, steps_per_epoch=n_batches, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pre.convert(char2int, feat2val, max_root - 2, max_word - 2, train_set=False)\n",
    "test_gen = pre.gen(test_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(infenc, infdec, inputs, n_steps):\n",
    "    # encode\n",
    "    state = infenc.predict(inputs)\n",
    "#     start of sequence input\n",
    "    target_seq = np.array([char2int['<']]*len(inputs[0])).reshape((len(inputs[0]), 1))\n",
    "#     start[0] = 1\n",
    "#     target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    outputs = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h = infdec.predict([target_seq, state])\n",
    "        # store prediction\n",
    "#         output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = h\n",
    "#         print(yhat.shape)\n",
    "        # update target sequence\n",
    "        target_seq = yhat.argmax(axis=2)\n",
    "#         print(target_seq.shape)\n",
    "        outputs.append(target_seq)\n",
    "    return np.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Accuracy: 61.72%\n"
     ]
    }
   ],
   "source": [
    "# shows sample examples and calculates accuracy\n",
    "test_batches = len(test_data[0]) // batch_size\n",
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(1):\n",
    "    # get data from test data generator\n",
    "    [root, feat, dec_in], y = next(test_gen)\n",
    "    pred = predict(encoder, decoder, [root, feat], max_word)\n",
    "    for k in range(batch_size):\n",
    "        indexes = pred[:, k].flatten()\n",
    "        r = ''.join(pre.index_to_word(root[k], int2char)).strip()[1:-1]\n",
    "        w = ''.join(pre.index_to_word(dec_in[k], int2char)).strip()[1:-1]\n",
    "        t = ''.join(pre.index_to_word(indexes, int2char)).strip()[:-1]\n",
    "        if w == t:\n",
    "            correct += 1\n",
    "        \n",
    "\n",
    "    total += batch_size\n",
    "    \n",
    "\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
